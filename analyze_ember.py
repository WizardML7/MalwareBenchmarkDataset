#!/usr/bin/python
''' Extracts some basic features from PE files. Many of the features
implemented have been used in previously published works. For more information,
check out the following resources:
* Schultz, et al., 2001: http://128.59.14.66/sites/default/files/binaryeval-ieeesp01.pdf
* Kolter and Maloof, 2006: http://www.jmlr.org/papers/volume7/kolter06a/kolter06a.pdf
* Shafiq et al., 2009: https://www.researchgate.net/profile/Fauzan_Mirza/publication/242084613_A_Framework_for_Efficient_Mining_of_Structural_Information_to_Detect_Zero-Day_Malicious_Portable_Executables/links/0c96052e191668c3d5000000.pdf
* Raman, 2012: http://2012.infosecsouthwest.com/files/speaker_materials/ISSW2012_Selecting_Features_to_Classify_Malware.pdf
* Saxe and Berlin, 2015: https://arxiv.org/pdf/1508.03096.pdf

It may be useful to do feature selection to reduce this set of features to a meaningful set
for your modeling problem.
'''

import re
import lief
import hashlib
import numpy as np
import os
import json
from sklearn.feature_extraction import FeatureHasher

import sys

LIEF_MAJOR, LIEF_MINOR, _ = lief.__version__.split('.')
LIEF_EXPORT_OBJECT = int(LIEF_MAJOR) > 0 or ( int(LIEF_MAJOR)==0 and int(LIEF_MINOR) >= 10 )
LIEF_HAS_SIGNATURE = int(LIEF_MAJOR) > 0 or (int(LIEF_MAJOR) == 0 and int(LIEF_MINOR) >= 11)

class FeatureType(object):
    ''' Base class from which each feature type may inherit '''

    name = ''
    dim = 0

    def __repr__(self):
        return '{}({})'.format(self.name, self.dim)

    def raw_features(self, bytez, lief_binary):
        ''' Generate a JSON-able representation of the file '''
        raise (NotImplementedError)

    def process_raw_features(self, raw_obj):
        ''' Generate a feature vector from the raw features '''
        raise (NotImplementedError)

    def feature_vector(self, bytez, lief_binary):
        ''' Directly calculate the feature vector from the sample itself. This should only be implemented differently
        if there are significant speedups to be gained from combining the two functions. '''
        return self.process_raw_features(self.raw_features(bytez, lief_binary))

class ByteHistogram(FeatureType):
    ''' Byte histogram (count + non-normalized) over the entire binary file '''

    name = 'histogram'
    dim = 256

    def __init__(self):
        super(FeatureType, self).__init__()

    def raw_features(self, bytez, lief_binary):
        counts = np.bincount(np.frombuffer(bytez, dtype=np.uint8), minlength=256)
        return counts.tolist()

    def process_raw_features(self, raw_obj):
        counts = np.array(raw_obj, dtype=np.float32)
        sum = counts.sum()
        normalized = counts / sum
        return normalized

class ByteEntropyHistogram(FeatureType):
    ''' 2d byte/entropy histogram based loosely on (Saxe and Berlin, 2015).
    This roughly approximates the joint probability of byte value and local entropy.
    See Section 2.1.1 in https://arxiv.org/pdf/1508.03096.pdf for more info.
    '''

    name = 'byteentropy'
    dim = 256

    def __init__(self, step=1024, window=2048):
        super(FeatureType, self).__init__()
        self.window = window
        self.step = step

    def _entropy_bin_counts(self, block):
        # coarse histogram, 16 bytes per bin
        c = np.bincount(block >> 4, minlength=16)  # 16-bin histogram
        p = c.astype(np.float32) / self.window
        wh = np.where(c)[0]
        H = np.sum(-p[wh] * np.log2(
            p[wh])) * 2  # * x2 b.c. we reduced information by half: 256 bins (8 bits) to 16 bins (4 bits)

        Hbin = int(H * 2)  # up to 16 bins (max entropy is 8 bits)
        if Hbin == 16:  # handle entropy = 8.0 bits
            Hbin = 15

        return Hbin, c

    def raw_features(self, bytez, lief_binary):
        output = np.zeros((16, 16), dtype=np.int64)
        a = np.frombuffer(bytez, dtype=np.uint8)
        if a.shape[0] < self.window:
            Hbin, c = self._entropy_bin_counts(a)
            output[Hbin, :] += c
        else:
            # strided trick from here: http://www.rigtorp.se/2011/01/01/rolling-statistics-numpy.html
            shape = a.shape[:-1] + (a.shape[-1] - self.window + 1, self.window)
            strides = a.strides + (a.strides[-1],)
            blocks = np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)[::self.step, :]

            # from the blocks, compute histogram
            for block in blocks:
                Hbin, c = self._entropy_bin_counts(block)
                output[Hbin, :] += c

        return output.flatten().tolist()

    def process_raw_features(self, raw_obj):
        counts = np.array(raw_obj, dtype=np.float32)
        sum = counts.sum()
        normalized = counts / sum
        return normalized

class SectionInfo(FeatureType):
    ''' Information about section names, sizes and entropy.  Uses hashing trick
    to summarize all this section info into a feature vector.
    '''

    name = 'section'
    dim = 5 + 50 + 50 + 50 + 50 + 50

    def __init__(self):
        super(FeatureType, self).__init__()

    @staticmethod
    def _properties(s):
        return [str(c).split('.')[-1] for c in s.characteristics_lists]

    def raw_features(self, bytez, lief_binary):
        if lief_binary is None:
            return {"entry": "", "sections": []}

        # properties of entry point, or if invalid, the first executable section

        try:
            if int(LIEF_MAJOR) > 0 or (int(LIEF_MAJOR) == 0 and int(LIEF_MINOR) >= 12):
                section = lief_binary.section_from_rva(lief_binary.entrypoint - lief_binary.imagebase)
                if section is None:
                    raise lief.not_found
                entry_section = section.name
            else: # lief < 0.12
                entry_section = lief_binary.section_from_offset(lief_binary.entrypoint).name
        except lief.not_found:
                # bad entry point, let's find the first executable section
                entry_section = ""
                for s in lief_binary.sections:
                    if lief.PE.SECTION_CHARACTERISTICS.MEM_EXECUTE in s.characteristics_lists:
                        entry_section = s.name
                        break

        raw_obj = {"entry": entry_section}
        raw_obj["sections"] = [{
            'name': s.name,
            'size': s.size,
            'entropy': s.entropy,
            'vsize': s.virtual_size,
            'props': self._properties(s)
        } for s in lief_binary.sections]
        return raw_obj

    def process_raw_features(self, raw_obj):
        sections = raw_obj['sections']
        general = [
            len(sections),  # total number of sections
            # number of sections with zero size
            sum(1 for s in sections if s['size'] == 0),
            # number of sections with an empty name
            sum(1 for s in sections if s['name'] == ""),
            # number of RX
            sum(1 for s in sections if 'MEM_READ' in s['props'] and 'MEM_EXECUTE' in s['props']),
            # number of W
            sum(1 for s in sections if 'MEM_WRITE' in s['props'])
        ]
        # gross characteristics of each section
        section_sizes = [(s['name'], s['size']) for s in sections]
        section_sizes_hashed = FeatureHasher(50, input_type="pair").transform([section_sizes]).toarray()[0]
        section_entropy = [(s['name'], s['entropy']) for s in sections]
        section_entropy_hashed = FeatureHasher(50, input_type="pair").transform([section_entropy]).toarray()[0]
        section_vsize = [(s['name'], s['vsize']) for s in sections]
        section_vsize_hashed = FeatureHasher(50, input_type="pair").transform([section_vsize]).toarray()[0]
        entry_name_hashed = FeatureHasher(50, input_type="string").transform([raw_obj['entry']]).toarray()[0]
        characteristics = [p for s in sections for p in s['props'] if s['name'] == raw_obj['entry']]
        characteristics_hashed = FeatureHasher(50, input_type="string").transform([characteristics]).toarray()[0]

        return np.hstack([
            general,
            section_sizes_hashed,
            section_entropy_hashed,
            section_vsize_hashed,
            entry_name_hashed,
            characteristics_hashed,
        ])

class ImportsInfo(FeatureType):
    ''' Information about imported libraries and functions.  Uses hashing trick
    to summarize this variable-length import info into a feature vector.
    '''

    name = 'imports'
    dim = 128

    def __init__(self):
        super(FeatureType, self).__init__()

    def raw_features(self, bytez, lief_binary):
        if lief_binary is None:
            return []

        return [(imp.name, e.name) for imp in lief_binary.imports for e in imp.entries]

    def process_raw_features(self, raw_obj):
        return FeatureHasher(self.dim, input_type="pair").transform([raw_obj]).toarray()[0]

class ExportsInfo(FeatureType):
    ''' Information about exported functions.  Uses hashing trick
    to summarize this variable-length export info into a feature vector.
    '''

    name = 'exports'
    dim = 128

    def __init__(self):
        super(FeatureType, self).__init__()

    def raw_features(self, bytez, lief_binary):
        if lief_binary is None:
            return []

        return [e.name for e in lief_binary.exported_functions]

    def process_raw_features(self, raw_obj):
        return FeatureHasher(self.dim, input_type="string").transform([raw_obj]).toarray()[0]

class DataDirectories(FeatureType):
    '''Information from the Data Directory of the binary.  For more info, see
    https://docs.microsoft.com/en-us/windows/desktop/debug/pe-format#optional-header-data-directories-image-only
    '''

    name = 'datadirectories'
    dim = 128

    def __init__(self):
        super(FeatureType, self).__init__()

    def raw_features(self, bytez, lief_binary):
        if lief_binary is None:
            return []

        if LIEF_EXPORT_OBJECT:
            return [str(d) for d in lief_binary.data_directories]
        else:
            return [d.type.name for d in lief_binary.data_directories]

    def process_raw_features(self, raw_obj):
        return FeatureHasher(self.dim, input_type="string").transform([raw_obj]).toarray()[0]

class HeaderInfo(FeatureType):
    '''General information about the binary'''

    name = 'header'
    dim = 62

    def __init__(self):
        super(FeatureType, self).__init__()

    def raw_features(self, bytez, lief_binary):
        if lief_binary is None:
            return {}

        return {
            "coff": {
                "timestamp": lief_binary.header.time_date_stamps,
                "machine": lief_binary.header.machine,
                "characteristics": list(lief_binary.header.characteristics)
            },
            "optional": {
                "subsystem": lief_binary.optional_header.subsystem,
                "dll_characteristics": list(lief_binary.optional_header.dll_characteristics),
                "magic": lief_binary.optional_header.magic,
                "major_image_version": lief_binary.optional_header.major_image_version,
                "minor_image_version": lief_binary.optional_header.minor_image_version,
                "major_linker_version": lief_binary.optional_header.major_linker_version,
                "minor_linker_version": lief_binary.optional_header.minor_linker_version,
                "major_operating_system_version": lief_binary.optional_header.major_operating_system_version,
                "minor_operating_system_version": lief_binary.optional_header.minor_operating_system_version,
                "major_subsystem_version": lief_binary.optional_header.major_subsystem_version,
                "minor_subsystem_version": lief_binary.optional_header.minor_subsystem_version,
                "sizeof_code": lief_binary.optional_header.sizeof_code,
                "sizeof_headers": lief_binary.optional_header.sizeof_headers,
                "sizeof_heap_commit": lief_binary.optional_header.sizeof_heap_commit,
                "loader_flags": lief_binary.optional_header.loader_flags
            }
        }

    def process_raw_features(self, raw_obj):
        vals = []

        # general header
        vals.append(raw_obj['coff']['timestamp'])
        vals.append(raw_obj['coff']['machine'])
        vals.extend([int(b) for b in list('{:016b}'.format(raw_obj['coff']['characteristics']))])

        # general optional_header
        vals.append(raw_obj['optional']['subsystem'])
        vals.extend([int(b) for b in list('{:016b}'.format(raw_obj['optional']['dll_characteristics']))])

        # everything else
        keys = [
            'magic',
            'major_image_version', 'minor_image_version',
            'major_linker_version', 'minor_linker_version',
            'major_operating_system_version', 'minor_operating_system_version',
            'major_subsystem_version', 'minor_subsystem_version',
            'sizeof_code',
            'sizeof_headers',
            'sizeof_heap_commit',
            'loader_flags'
        ]
        vals.extend([raw_obj['optional'][k] for k in keys])

        return np.array(vals, dtype=np.float32)

class StringExtractor(FeatureType):
    ''' Extracts all strings from the byte stream. Applies some light normalization to the data
    to prevent overly unique strings from polluting the results. '''
    name = 'strings'
    dim = 128

    def __init__(self, min_length=2):
        super(FeatureType, self).__init__()
        self.min_length = min_length

    def raw_features(self, bytez, lief_binary):
        strings = set()
        try:
            bytez = bytez.decode('utf-8', errors='ignore')
        except:
            return []
        for s in re.findall("[\x20-\x7f]{%d,}" % self.min_length, bytez):
            # the min length parameter on findall ensures that there are no strings < min_length
            strings.add(s)
        return list(strings)

    def process_raw_features(self, raw_obj):
        return FeatureHasher(self.dim, input_type="string").transform([raw_obj]).toarray()[0]

class GeneralFileInfo(FeatureType):
    ''' General information about the binary '''

    name = 'general'
    dim = 10

    def __init__(self):
        super(FeatureType, self).__init__()

    def raw_features(self, bytez, lief_binary):
        return {
            "size": len(bytez),
            "vsize": lief_binary.virtual_size if lief_binary is not None else 0
        }

    def process_raw_features(self, raw_obj):
        return np.array([raw_obj['size'], raw_obj['vsize']])

class SignatureInfo(FeatureType):
    ''' Information about the signature '''

    name = 'signature'
    dim = 10

    def __init__(self):
        super(FeatureType, self).__init__()

    def raw_features(self, bytez, lief_binary):
        if lief_binary is None or not LIEF_HAS_SIGNATURE:
            return {
                "present": 0
            }
        sig = lief_binary.signatures
        if len(sig) == 0:
            return {
                "present": 0
            }
        return {
            "present": 1
        }

    def process_raw_features(self, raw_obj):
        return np.array([raw_obj['present']])

def get_available_features():
    ''' Returns a list of available features '''
    features = [
        ByteHistogram(),
        ByteEntropyHistogram(),
        SectionInfo(),
        ImportsInfo(),
        ExportsInfo(),
        DataDirectories(),
        HeaderInfo(),
        StringExtractor(),
        GeneralFileInfo(),
        SignatureInfo()
    ]
    return {feat.name: feat for feat in features}

def raw_feature_names():
    ''' Returns a list of available features '''
    return list(get_available_features().keys())

def raw_features(bytez, lief_binary, selected_features=None):
    ''' Extracts raw features from the binary.
    Args:
        bytez: The binary byte stream
        lief_binary: The lief binary object
        selected_features: List of features to extract. If None, all features are extracted.
    Returns:
        A dictionary of raw features
    '''
    features = get_available_features()
    if selected_features is not None:
        features = {k: v for k, v in features.items() if k in selected_features}
    raw_feature_set = {feat.name: feat.raw_features(bytez, lief_binary) for feat in features.values()}
    return raw_feature_set

def process_raw_features(raw_obj):
    ''' Process raw features into a feature vector
    Args:
        raw_obj: A dictionary of raw features
    Returns:
        A feature vector
    '''
    features = get_available_features()
    feature_vectors = [feat.process_raw_features(raw_obj[feat.name]) for feat in features.values()]
    return np.hstack(feature_vectors)

def sha256_file(filename):
    ''' Calculates the sha256 of the file
    Args:
        filename: The name of the file
    Returns:
        The sha256 of the file
    '''
    h = hashlib.sha256()
    with open(filename, 'rb') as f:
        data = f.read(1024)
        while data:
            h.update(data)
            data = f.read(1024)
    return h.hexdigest()

def main(filename, output_file):
    with open(filename, 'rb') as f:
        bytez = f.read()

    lief_binary = None
    try:
        lief_binary = lief.parse(bytez)
    except:
        pass

    raw = raw_features(bytez, lief_binary)

    with open(output_file, 'w') as f:
        json.dump(raw, f, indent=4)

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Extract raw features from a binary')
    parser.add_argument('filename', type=str, help='The name of the file to process')
    parser.add_argument('output_file', type=str, help='The name of the output file')

    args = parser.parse_args()
    main(args.filename, args.output_file)
